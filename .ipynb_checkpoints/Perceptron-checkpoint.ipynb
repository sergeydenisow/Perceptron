{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Линейная регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:28:34.900077Z",
     "start_time": "2019-11-06T12:28:34.399089Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import autograd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зарузка данных.\n",
    "\n",
    "Стоимость недвижимости в Калифорнии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.data.shape, housing.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(housing.data), type(housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scaler.fit_transform(housing.data, housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.34476576,  0.98214266,  0.62855945, ..., -0.04959654,\n",
       "         1.05254828, -1.32783522],\n",
       "       [ 2.33223796, -0.60701891,  0.32704136, ..., -0.09251223,\n",
       "         1.04318455, -1.32284391],\n",
       "       [ 1.7826994 ,  1.85618152,  1.15562047, ..., -0.02584253,\n",
       "         1.03850269, -1.33282653],\n",
       "       ...,\n",
       "       [-1.14259331, -0.92485123, -0.09031802, ..., -0.0717345 ,\n",
       "         1.77823747, -0.8237132 ],\n",
       "       [-1.05458292, -0.84539315, -0.04021111, ..., -0.09122515,\n",
       "         1.77823747, -0.87362627],\n",
       "       [-0.78012947, -1.00430931, -0.07044252, ..., -0.04368215,\n",
       "         1.75014627, -0.83369581]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = torch.tensor(housing.data)\n",
    "# target = torch.tensor(housing.target)\n",
    "# data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(data).float()\n",
    "target = torch.from_numpy(housing.target).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20640, 8]), torch.Size([20640]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:41:59.728821Z",
     "start_time": "2019-11-06T13:41:59.450748Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.subplot(131)\n",
    "# plt.scatter(features[:, 0], labels, 1)\n",
    "# plt.subplot(132)\n",
    "# plt.scatter(features[:, 1], labels, 1)\n",
    "# plt.subplot(133)\n",
    "# plt.scatter(features[:, 0], features[:, 1], 1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:40:23.439886Z",
     "start_time": "2019-11-06T12:40:23.437308Z"
    }
   },
   "source": [
    "## Линейная регрессия на torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:52:12.812804Z",
     "start_time": "2019-11-06T13:52:12.809805Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:52:13.355499Z",
     "start_time": "2019-11-06T13:52:13.348636Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataset = TensorDataset(data, target)\n",
    "\n",
    "# data_iter = DataLoader(dataset, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:52:13.120962Z",
     "start_time": "2019-11-06T13:52:13.116472Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14447, 6193)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_dataset.dataset.tensors[0], train_dataset.dataset.tensors[1]\n",
    "X_test, y_test = test_dataset.dataset.tensors[0], test_dataset.dataset.tensors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.dataset.tensors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly reading mini-batches\n",
    "data_train = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "data_test = DataLoader(test_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1951,  1.3794, -0.2751,  0.0321, -0.9214, -0.0384, -0.6376,  0.1596],\n",
      "        [-0.1786, -0.2097, -0.4395, -0.1233, -0.4790, -0.0634, -0.8577,  0.6986],\n",
      "        [-0.5241,  1.0616, -0.4627, -0.0755,  0.5409,  0.0364, -0.7874,  0.6038],\n",
      "        [-1.1821, -0.2097,  0.0691, -0.6260, -1.2508, -0.1223,  0.9917, -0.6390],\n",
      "        [-1.1206,  1.3794, -0.0574, -0.0483, -0.8967,  0.0279,  1.5067, -1.0483],\n",
      "        [-0.7171,  0.9821, -0.4689, -0.3059, -0.6971,  0.1267, -0.7968,  0.6787],\n",
      "        [-0.0284, -0.6070,  0.2913,  0.1092,  0.6928, -0.0186, -0.7312,  0.8484],\n",
      "        [ 0.3133,  0.2670, -0.0434, -0.0500, -0.0675,  0.0554, -0.8155,  0.6487],\n",
      "        [-0.3450,  1.0616, -0.2609, -0.0976,  0.4544, -0.0185,  0.8091, -1.1681],\n",
      "        [-0.2773,  1.8562, -0.3094, -0.1127, -0.7925, -0.0512,  1.0057, -1.3428],\n",
      "        [ 0.1661, -1.1632, -0.5474, -0.1043, -0.2062, -0.1207, -0.8951,  0.7585],\n",
      "        [ 0.3793,  1.6178,  0.1291, -0.1107, -0.5788, -0.0435,  0.9776, -1.4476],\n",
      "        [-0.8136,  0.2670,  0.3702, -0.0169, -0.7625, -0.0291,  1.9421, -1.2929],\n",
      "        [-0.3783, -0.6070, -0.3805, -0.1723,  0.7246,  0.2450, -0.8998,  0.8534],\n",
      "        [ 0.4210, -0.7659,  0.3883,  0.0837, -0.5064, -0.0293,  1.3101, -1.6672],\n",
      "        [-0.2061,  0.4259, -0.3252, -0.1593, -0.4490, -0.0621, -0.7921,  0.7685]]) tensor([2.2120, 1.8750, 1.7750, 0.8500, 1.1040, 1.1810, 2.5870, 1.3810, 1.9970,\n",
      "        2.0130, 1.8890, 2.5970, 0.6960, 1.5280, 2.6980, 1.6900])\n"
     ]
    }
   ],
   "source": [
    "# Read a batch to see how it works\n",
    "for X, y in data_iter:\n",
    "    print(X, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:01:54.637870Z",
     "start_time": "2019-11-06T15:01:54.634430Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].weight.data = torch.rand((1,8), requires_grad=True)\n",
    "model[0].bias.data = torch.rand(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8211, 0.5216, 0.5485, 0.0045, 0.3370, 0.1420, 0.9658, 0.8474]]),\n",
       " tensor([0.5614]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.data, model[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:00:35.708316Z",
     "start_time": "2019-11-06T15:00:35.704362Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model[0].weight.data = torch.zeros((1, 8), requires_grad=True)\n",
    "# model[0].bias.data = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:01:56.233161Z",
     "start_time": "2019-11-06T15:01:56.230196Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:01:59.643238Z",
     "start_time": "2019-11-06T15:01:59.640268Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = torch.optim.RMSprop(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:02:03.375656Z",
     "start_time": "2019-11-06T15:02:00.252186Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergey/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/sergey/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([20640])) that is different to the input size (torch.Size([20640, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 4.215921\n",
      "w tensor([[ 0.7040,  0.4776,  0.4823, -0.0271,  0.3042,  0.1249,  0.9280,  0.8668]])\n",
      "b tensor([0.6985])\n",
      "epoch 2, loss: 3.653850\n",
      "w tensor([[ 0.5977,  0.4364,  0.4388, -0.0458,  0.2735,  0.1195,  0.9008,  0.8717]])\n",
      "b tensor([0.8238])\n",
      "epoch 3, loss: 3.177130\n",
      "w tensor([[ 0.4950,  0.3965,  0.4040, -0.0611,  0.2456,  0.1141,  0.8760,  0.8683]])\n",
      "b tensor([0.9483])\n",
      "epoch 4, loss: 2.748645\n",
      "w tensor([[ 0.3956,  0.3533,  0.3545, -0.0831,  0.2143,  0.1077,  0.8539,  0.8570]])\n",
      "b tensor([1.0720])\n",
      "epoch 5, loss: 2.394890\n",
      "w tensor([[ 0.3023,  0.3090,  0.3107, -0.1034,  0.1844,  0.1009,  0.8302,  0.8386]])\n",
      "b tensor([1.1944])\n",
      "epoch 6, loss: 2.102609\n",
      "w tensor([[ 0.2165,  0.2669,  0.2586, -0.1290,  0.1526,  0.0950,  0.8063,  0.8159]])\n",
      "b tensor([1.3144])\n",
      "epoch 7, loss: 1.871902\n",
      "w tensor([[ 0.1540,  0.2248,  0.1971, -0.1596,  0.1254,  0.0725,  0.7779,  0.7881]])\n",
      "b tensor([1.4321])\n",
      "epoch 8, loss: 1.708393\n",
      "w tensor([[ 0.1164,  0.1838,  0.1489, -0.1713,  0.0951,  0.0670,  0.7461,  0.7543]])\n",
      "b tensor([1.5450])\n",
      "epoch 9, loss: 1.589763\n",
      "w tensor([[ 0.0952,  0.1507,  0.1207, -0.1721,  0.0722,  0.0542,  0.7093,  0.7191]])\n",
      "b tensor([1.6515])\n",
      "epoch 10, loss: 1.505504\n",
      "w tensor([[ 0.0888,  0.1242,  0.1017, -0.1683,  0.0526,  0.0492,  0.6673,  0.6792]])\n",
      "b tensor([1.7500])\n",
      "epoch 11, loss: 1.448904\n",
      "w tensor([[ 0.0852,  0.1041,  0.0876, -0.1617,  0.0348,  0.0424,  0.6284,  0.6332]])\n",
      "b tensor([1.8345])\n",
      "epoch 12, loss: 1.412423\n",
      "w tensor([[ 0.0807,  0.0890,  0.0780, -0.1538,  0.0261,  0.0364,  0.5848,  0.5882]])\n",
      "b tensor([1.9044])\n",
      "epoch 13, loss: 1.389936\n",
      "w tensor([[ 0.0787,  0.0806,  0.0635, -0.1433,  0.0236,  0.0314,  0.5391,  0.5411]])\n",
      "b tensor([1.9577])\n",
      "epoch 14, loss: 1.377313\n",
      "w tensor([[ 0.0813,  0.0753,  0.0619, -0.1357,  0.0251,  0.0262,  0.4949,  0.4988]])\n",
      "b tensor([1.9938])\n",
      "epoch 15, loss: 1.368342\n",
      "w tensor([[ 0.0790,  0.0726,  0.0593, -0.1281,  0.0193,  0.0208,  0.4540,  0.4553]])\n",
      "b tensor([2.0197])\n",
      "epoch 16, loss: 1.361047\n",
      "w tensor([[ 0.0732,  0.0659,  0.0549, -0.1177,  0.0196,  0.0108,  0.4132,  0.4169]])\n",
      "b tensor([2.0371])\n",
      "epoch 17, loss: 1.355919\n",
      "w tensor([[ 0.0714,  0.0615,  0.0527, -0.1071,  0.0199,  0.0060,  0.3744,  0.3788]])\n",
      "b tensor([2.0484])\n",
      "epoch 18, loss: 1.351684\n",
      "w tensor([[ 0.0698,  0.0548,  0.0490, -0.0970,  0.0140,  0.0015,  0.3364,  0.3418]])\n",
      "b tensor([2.0555])\n",
      "epoch 19, loss: 1.348280\n",
      "w tensor([[ 0.0669,  0.0517,  0.0440, -0.0891,  0.0156, -0.0056,  0.3037,  0.3057]])\n",
      "b tensor([2.0602])\n",
      "epoch 20, loss: 1.345606\n",
      "w tensor([[ 0.0686,  0.0497,  0.0392, -0.0765,  0.0175, -0.0087,  0.2703,  0.2722]])\n",
      "b tensor([2.0633])\n",
      "epoch 21, loss: 1.343695\n",
      "w tensor([[ 0.0682,  0.0465,  0.0351, -0.0684,  0.0119, -0.0194,  0.2395,  0.2423]])\n",
      "b tensor([2.0647])\n",
      "epoch 22, loss: 1.340826\n",
      "w tensor([[ 0.0605,  0.0389,  0.0293, -0.0560,  0.0125, -0.0197,  0.2123,  0.2127]])\n",
      "b tensor([2.0656])\n",
      "epoch 23, loss: 1.339460\n",
      "w tensor([[ 0.0610,  0.0385,  0.0222, -0.0502,  0.0128, -0.0177,  0.1832,  0.1871]])\n",
      "b tensor([2.0657])\n",
      "epoch 24, loss: 1.338371\n",
      "w tensor([[ 0.0626,  0.0343,  0.0165, -0.0422,  0.0100, -0.0168,  0.1602,  0.1621]])\n",
      "b tensor([2.0669])\n",
      "epoch 25, loss: 1.337506\n",
      "w tensor([[ 0.0639,  0.0317,  0.0129, -0.0323,  0.0052, -0.0157,  0.1391,  0.1403]])\n",
      "b tensor([2.0678])\n",
      "epoch 26, loss: 1.336854\n",
      "w tensor([[ 0.0651,  0.0315,  0.0068, -0.0239,  0.0101, -0.0166,  0.1189,  0.1195]])\n",
      "b tensor([2.0679])\n",
      "epoch 27, loss: 1.335692\n",
      "w tensor([[ 0.0609,  0.0263, -0.0016, -0.0159,  0.0070, -0.0154,  0.0997,  0.1031]])\n",
      "b tensor([2.0681])\n",
      "epoch 28, loss: 1.336038\n",
      "w tensor([[ 0.0644,  0.0303, -0.0055, -0.0101,  0.0069, -0.0232,  0.0848,  0.0883]])\n",
      "b tensor([2.0684])\n",
      "epoch 29, loss: 1.335124\n",
      "w tensor([[ 0.0611,  0.0246, -0.0101, -0.0020,  0.0091, -0.0209,  0.0715,  0.0723]])\n",
      "b tensor([2.0684])\n",
      "epoch 30, loss: 1.335089\n",
      "w tensor([[ 0.0628,  0.0208, -0.0119,  0.0037,  0.0064, -0.0214,  0.0570,  0.0590]])\n",
      "b tensor([2.0679])\n",
      "epoch 31, loss: 1.334594\n",
      "w tensor([[ 0.0608,  0.0201, -0.0179,  0.0095,  0.0056, -0.0190,  0.0455,  0.0469]])\n",
      "b tensor([2.0688])\n",
      "epoch 32, loss: 1.334515\n",
      "w tensor([[ 0.0604,  0.0214, -0.0218,  0.0115,  0.0041, -0.0189,  0.0366,  0.0361]])\n",
      "b tensor([2.0687])\n",
      "epoch 33, loss: 1.334630\n",
      "w tensor([[ 0.0629,  0.0161, -0.0219,  0.0155,  0.0031, -0.0177,  0.0275,  0.0283]])\n",
      "b tensor([2.0688])\n",
      "epoch 34, loss: 1.334647\n",
      "w tensor([[ 0.0638,  0.0147, -0.0247,  0.0195,  0.0057, -0.0164,  0.0182,  0.0219]])\n",
      "b tensor([2.0680])\n",
      "epoch 35, loss: 1.334821\n",
      "w tensor([[ 0.0650,  0.0162, -0.0217,  0.0227,  0.0033, -0.0136,  0.0138,  0.0137]])\n",
      "b tensor([2.0683])\n",
      "epoch 36, loss: 1.334025\n",
      "w tensor([[ 0.0572,  0.0126, -0.0243,  0.0267,  0.0012, -0.0139,  0.0068,  0.0074]])\n",
      "b tensor([2.0688])\n",
      "epoch 37, loss: 1.334780\n",
      "w tensor([[ 0.0621,  0.0130, -0.0273,  0.0248,  0.0018, -0.0209, -0.0025,  0.0027]])\n",
      "b tensor([2.0691])\n",
      "epoch 38, loss: 1.334341\n",
      "w tensor([[ 0.0584,  0.0115, -0.0293,  0.0263,  0.0027, -0.0193, -0.0073, -0.0038]])\n",
      "b tensor([2.0683])\n",
      "epoch 39, loss: 1.334375\n",
      "w tensor([[ 0.0591,  0.0100, -0.0297,  0.0241,  0.0032, -0.0169, -0.0106, -0.0087]])\n",
      "b tensor([2.0680])\n",
      "epoch 40, loss: 1.334558\n",
      "w tensor([[ 0.0600,  0.0135, -0.0295,  0.0281, -0.0029, -0.0151, -0.0154, -0.0124]])\n",
      "b tensor([2.0682])\n",
      "epoch 41, loss: 1.334295\n",
      "w tensor([[ 0.0576,  0.0125, -0.0324,  0.0251,  0.0029, -0.0137, -0.0191, -0.0165]])\n",
      "b tensor([2.0684])\n",
      "epoch 42, loss: 1.334705\n",
      "w tensor([[ 0.0604,  0.0081, -0.0286,  0.0274,  0.0035, -0.0163, -0.0237, -0.0189]])\n",
      "b tensor([2.0682])\n",
      "epoch 43, loss: 1.334491\n",
      "w tensor([[ 0.0582,  0.0079, -0.0284,  0.0296,  0.0023, -0.0170, -0.0226, -0.0244]])\n",
      "b tensor([2.0679])\n",
      "epoch 44, loss: 1.334776\n",
      "w tensor([[ 0.0600,  0.0073, -0.0280,  0.0292,  0.0017, -0.0168, -0.0287, -0.0258]])\n",
      "b tensor([2.0684])\n",
      "epoch 45, loss: 1.335038\n",
      "w tensor([[ 0.0616,  0.0109, -0.0281,  0.0259,  0.0025, -0.0147, -0.0331, -0.0285]])\n",
      "b tensor([2.0686])\n",
      "epoch 46, loss: 1.335497\n",
      "w tensor([[ 0.0640,  0.0114, -0.0262,  0.0273,  0.0029, -0.0178, -0.0359, -0.0310]])\n",
      "b tensor([2.0693])\n",
      "epoch 47, loss: 1.335027\n",
      "w tensor([[ 0.0603,  0.0115, -0.0306,  0.0259,  0.0029, -0.0161, -0.0375, -0.0353]])\n",
      "b tensor([2.0692])\n",
      "epoch 48, loss: 1.335282\n",
      "w tensor([[ 0.0611,  0.0103, -0.0256,  0.0314,  0.0012, -0.0192, -0.0370, -0.0375]])\n",
      "b tensor([2.0691])\n",
      "epoch 49, loss: 1.335137\n",
      "w tensor([[ 0.0603,  0.0109, -0.0258,  0.0289,  0.0026, -0.0174, -0.0350, -0.0399]])\n",
      "b tensor([2.0689])\n",
      "epoch 50, loss: 1.334730\n",
      "w tensor([[ 0.0565,  0.0097, -0.0282,  0.0279,  0.0003, -0.0176, -0.0390, -0.0373]])\n",
      "b tensor([2.0689])\n",
      "epoch 51, loss: 1.334934\n",
      "w tensor([[ 0.0589,  0.0073, -0.0293,  0.0252, -0.0008, -0.0155, -0.0414, -0.0385]])\n",
      "b tensor([2.0687])\n",
      "epoch 52, loss: 1.335060\n",
      "w tensor([[ 0.0587,  0.0095, -0.0287,  0.0265,  0.0013, -0.0177, -0.0438, -0.0378]])\n",
      "b tensor([2.0678])\n",
      "epoch 53, loss: 1.335123\n",
      "w tensor([[ 0.0587,  0.0095, -0.0259,  0.0278,  0.0005, -0.0187, -0.0421, -0.0427]])\n",
      "b tensor([2.0679])\n",
      "epoch 54, loss: 1.335168\n",
      "w tensor([[ 0.0589,  0.0124, -0.0259,  0.0273, -0.0003, -0.0170, -0.0435, -0.0425]])\n",
      "b tensor([2.0679])\n",
      "epoch 55, loss: 1.334893\n",
      "w tensor([[ 0.0559,  0.0119, -0.0278,  0.0271,  0.0016, -0.0174, -0.0461, -0.0415]])\n",
      "b tensor([2.0681])\n",
      "epoch 56, loss: 1.335066\n",
      "w tensor([[ 0.0577,  0.0086, -0.0260,  0.0275,  0.0010, -0.0179, -0.0466, -0.0418]])\n",
      "b tensor([2.0677])\n",
      "epoch 57, loss: 1.334910\n",
      "w tensor([[ 0.0569,  0.0062, -0.0250,  0.0291,  0.0046, -0.0164, -0.0454, -0.0447]])\n",
      "b tensor([2.0679])\n",
      "epoch 58, loss: 1.335163\n",
      "w tensor([[ 0.0590,  0.0111, -0.0258,  0.0256,  0.0003, -0.0147, -0.0444, -0.0475]])\n",
      "b tensor([2.0683])\n",
      "epoch 59, loss: 1.335270\n",
      "w tensor([[ 0.0590,  0.0114, -0.0260,  0.0274,  0.0005, -0.0151, -0.0506, -0.0442]])\n",
      "b tensor([2.0677])\n",
      "epoch 60, loss: 1.335239\n",
      "w tensor([[ 0.0592,  0.0059, -0.0224,  0.0304,  0.0058, -0.0136, -0.0487, -0.0466]])\n",
      "b tensor([2.0680])\n",
      "epoch 61, loss: 1.335071\n",
      "w tensor([[ 0.0583,  0.0076, -0.0254,  0.0281,  0.0021, -0.0139, -0.0488, -0.0473]])\n",
      "b tensor([2.0677])\n",
      "epoch 62, loss: 1.335155\n",
      "w tensor([[ 0.0575,  0.0092, -0.0246,  0.0296,  0.0008, -0.0180, -0.0477, -0.0492]])\n",
      "b tensor([2.0677])\n",
      "epoch 63, loss: 1.334938\n",
      "w tensor([[ 0.0559,  0.0086, -0.0255,  0.0300,  0.0019, -0.0171, -0.0487, -0.0486]])\n",
      "b tensor([2.0679])\n",
      "epoch 64, loss: 1.335037\n",
      "w tensor([[ 0.0568,  0.0071, -0.0246,  0.0294, -0.0004, -0.0166, -0.0488, -0.0496]])\n",
      "b tensor([2.0680])\n",
      "epoch 65, loss: 1.334937\n",
      "w tensor([[ 0.0560,  0.0088, -0.0250,  0.0269, -0.0022, -0.0144, -0.0487, -0.0505]])\n",
      "b tensor([2.0677])\n",
      "epoch 66, loss: 1.334977\n",
      "w tensor([[ 0.0552,  0.0120, -0.0239,  0.0275, -0.0013, -0.0138, -0.0515, -0.0507]])\n",
      "b tensor([2.0679])\n",
      "epoch 67, loss: 1.335019\n",
      "w tensor([[ 0.0555,  0.0055, -0.0226,  0.0260,  0.0041, -0.0167, -0.0525, -0.0484]])\n",
      "b tensor([2.0680])\n",
      "epoch 68, loss: 1.334980\n",
      "w tensor([[ 0.0558,  0.0062, -0.0244,  0.0224, -0.0019, -0.0156, -0.0498, -0.0508]])\n",
      "b tensor([2.0681])\n",
      "epoch 69, loss: 1.335244\n",
      "w tensor([[ 0.0572,  0.0093, -0.0245,  0.0215, -0.0033, -0.0158, -0.0498, -0.0535]])\n",
      "b tensor([2.0687])\n",
      "epoch 70, loss: 1.335521\n",
      "w tensor([[ 0.0592,  0.0065, -0.0191,  0.0270, -0.0002, -0.0153, -0.0540, -0.0499]])\n",
      "b tensor([2.0684])\n",
      "epoch 71, loss: 1.335105\n",
      "w tensor([[ 0.0559,  0.0084, -0.0227,  0.0265,  0.0002, -0.0148, -0.0555, -0.0502]])\n",
      "b tensor([2.0686])\n",
      "epoch 72, loss: 1.334725\n",
      "w tensor([[ 0.0515,  0.0092, -0.0220,  0.0299,  0.0008, -0.0169, -0.0527, -0.0524]])\n",
      "b tensor([2.0680])\n",
      "epoch 73, loss: 1.335166\n",
      "w tensor([[ 0.0562,  0.0081, -0.0226,  0.0270, -0.0015, -0.0160, -0.0545, -0.0531]])\n",
      "b tensor([2.0683])\n",
      "epoch 74, loss: 1.335297\n",
      "w tensor([[ 0.0571,  0.0078, -0.0226,  0.0243, -0.0007, -0.0170, -0.0553, -0.0505]])\n",
      "b tensor([2.0683])\n",
      "epoch 75, loss: 1.334970\n",
      "w tensor([[ 0.0536,  0.0074, -0.0259,  0.0238,  0.0001, -0.0195, -0.0547, -0.0519]])\n",
      "b tensor([2.0678])\n",
      "epoch 76, loss: 1.335025\n",
      "w tensor([[ 0.0548,  0.0073, -0.0229,  0.0260,  0.0021, -0.0175, -0.0543, -0.0520]])\n",
      "b tensor([2.0683])\n",
      "epoch 77, loss: 1.335021\n",
      "w tensor([[ 0.0543,  0.0092, -0.0197,  0.0260,  0.0018, -0.0150, -0.0549, -0.0516]])\n",
      "b tensor([2.0685])\n",
      "epoch 78, loss: 1.334614\n",
      "w tensor([[ 0.0508,  0.0102, -0.0211,  0.0258, -0.0003, -0.0130, -0.0533, -0.0540]])\n",
      "b tensor([2.0685])\n",
      "epoch 79, loss: 1.334619\n",
      "w tensor([[ 0.0504,  0.0081, -0.0212,  0.0263,  0.0013, -0.0144, -0.0565, -0.0522]])\n",
      "b tensor([2.0682])\n",
      "epoch 80, loss: 1.334632\n",
      "w tensor([[ 0.0517,  0.0068, -0.0236,  0.0249,  0.0021, -0.0139, -0.0541, -0.0551]])\n",
      "b tensor([2.0675])\n",
      "epoch 81, loss: 1.334807\n",
      "w tensor([[ 0.0534,  0.0060, -0.0222,  0.0254,  0.0042, -0.0119, -0.0568, -0.0526]])\n",
      "b tensor([2.0676])\n",
      "epoch 82, loss: 1.335094\n",
      "w tensor([[ 0.0559,  0.0109, -0.0239,  0.0238,  0.0004, -0.0123, -0.0552, -0.0549]])\n",
      "b tensor([2.0683])\n",
      "epoch 83, loss: 1.334769\n",
      "w tensor([[ 0.0538,  0.0085, -0.0240,  0.0248,  0.0020, -0.0106, -0.0532, -0.0559]])\n",
      "b tensor([2.0685])\n",
      "epoch 84, loss: 1.334989\n",
      "w tensor([[ 0.0544,  0.0079, -0.0219,  0.0246,  0.0019, -0.0152, -0.0555, -0.0521]])\n",
      "b tensor([2.0675])\n",
      "epoch 85, loss: 1.334813\n",
      "w tensor([[ 0.0536,  0.0059, -0.0226,  0.0252,  0.0023, -0.0128, -0.0559, -0.0510]])\n",
      "b tensor([2.0682])\n",
      "epoch 86, loss: 1.334759\n",
      "w tensor([[ 0.0534,  0.0071, -0.0216,  0.0250, -0.0008, -0.0113, -0.0532, -0.0535]])\n",
      "b tensor([2.0683])\n",
      "epoch 87, loss: 1.334749\n",
      "w tensor([[ 0.0528,  0.0098, -0.0203,  0.0231,  0.0003, -0.0103, -0.0514, -0.0547]])\n",
      "b tensor([2.0679])\n",
      "epoch 88, loss: 1.334659\n",
      "w tensor([[ 0.0520,  0.0093, -0.0199,  0.0259,  0.0011, -0.0086, -0.0545, -0.0526]])\n",
      "b tensor([2.0678])\n",
      "epoch 89, loss: 1.334971\n",
      "w tensor([[ 0.0552,  0.0074, -0.0215,  0.0220,  0.0044, -0.0096, -0.0557, -0.0498]])\n",
      "b tensor([2.0682])\n",
      "epoch 90, loss: 1.334576\n",
      "w tensor([[ 0.0526,  0.0038, -0.0220,  0.0233, -0.0003, -0.0077, -0.0541, -0.0522]])\n",
      "b tensor([2.0688])\n",
      "epoch 91, loss: 1.335059\n",
      "w tensor([[ 0.0562,  0.0016, -0.0210,  0.0238,  0.0019, -0.0122, -0.0552, -0.0524]])\n",
      "b tensor([2.0686])\n",
      "epoch 92, loss: 1.335029\n",
      "w tensor([[ 0.0563,  0.0066, -0.0217,  0.0233,  0.0002, -0.0109, -0.0534, -0.0531]])\n",
      "b tensor([2.0684])\n",
      "epoch 93, loss: 1.334549\n",
      "w tensor([[ 5.1229e-02,  8.7299e-03, -2.1118e-02,  2.5705e-02, -9.2376e-05,\n",
      "         -1.0832e-02, -5.3323e-02, -4.9887e-02]])\n",
      "b tensor([2.0683])\n",
      "epoch 94, loss: 1.334755\n",
      "w tensor([[ 0.0543,  0.0063, -0.0206,  0.0255,  0.0014, -0.0093, -0.0515, -0.0508]])\n",
      "b tensor([2.0677])\n",
      "epoch 95, loss: 1.334864\n",
      "w tensor([[ 0.0552,  0.0066, -0.0217,  0.0240,  0.0028, -0.0104, -0.0526, -0.0501]])\n",
      "b tensor([2.0675])\n",
      "epoch 96, loss: 1.334561\n",
      "w tensor([[ 0.0518,  0.0075, -0.0207,  0.0252,  0.0014, -0.0109, -0.0514, -0.0510]])\n",
      "b tensor([2.0671])\n",
      "epoch 97, loss: 1.334875\n",
      "w tensor([[ 0.0546,  0.0080, -0.0201,  0.0228, -0.0021, -0.0098, -0.0525, -0.0505]])\n",
      "b tensor([2.0675])\n",
      "epoch 98, loss: 1.334521\n",
      "w tensor([[ 0.0518,  0.0087, -0.0224,  0.0232, -0.0019, -0.0082, -0.0523, -0.0486]])\n",
      "b tensor([2.0678])\n",
      "epoch 99, loss: 1.334322\n",
      "w tensor([[ 0.0498,  0.0064, -0.0201,  0.0272,  0.0005, -0.0076, -0.0517, -0.0499]])\n",
      "b tensor([2.0687])\n",
      "epoch 100, loss: 1.334588\n",
      "w tensor([[ 0.0519,  0.0097, -0.0205,  0.0256, -0.0003, -0.0091, -0.0514, -0.0513]])\n",
      "b tensor([2.0689])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        \n",
    "        output = model(X)\n",
    "        l = loss(output, y)\n",
    "        # l = loss(model.forward(X), y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(model(data), target)\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))\n",
    "    print('w', model[0].weight.data)\n",
    "    print('b', model[0].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:02:10.986551Z",
     "start_time": "2019-11-06T15:02:10.979650Z"
    }
   },
   "outputs": [],
   "source": [
    "# w = model[0].weight.data\n",
    "# print('Error in estimating w', true_w.reshape(w.shape) - w)\n",
    "# b = model[0].bias.data\n",
    "# print('Error in estimating b', true_b - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный байесовский классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     model.to(device)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergey/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/sergey/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([15])) that is different to the input size (torch.Size([15, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/sergey/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([20640])) that is different to the input size (torch.Size([20640, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 6.090577602386475\n",
      "epoch 1, loss 5.705268383026123\n",
      "epoch 2, loss 5.335746765136719\n",
      "epoch 3, loss 4.985158443450928\n",
      "epoch 4, loss 4.652167320251465\n",
      "epoch 5, loss 4.335914611816406\n",
      "epoch 6, loss 4.037074089050293\n",
      "epoch 7, loss 3.7559974193573\n",
      "epoch 8, loss 3.491419792175293\n",
      "epoch 9, loss 3.245523452758789\n",
      "epoch 10, loss 3.013486623764038\n",
      "epoch 11, loss 2.8005905151367188\n",
      "epoch 12, loss 2.6015474796295166\n",
      "epoch 13, loss 2.4199671745300293\n",
      "epoch 14, loss 2.2540764808654785\n",
      "epoch 15, loss 2.102977991104126\n",
      "epoch 16, loss 1.9684391021728516\n",
      "epoch 17, loss 1.850356101989746\n",
      "epoch 18, loss 1.7490167617797852\n",
      "epoch 19, loss 1.6625043153762817\n",
      "epoch 20, loss 1.5902018547058105\n",
      "epoch 21, loss 1.5336171388626099\n",
      "epoch 22, loss 1.4899613857269287\n",
      "epoch 23, loss 1.4587328433990479\n",
      "epoch 24, loss 1.435545802116394\n",
      "epoch 25, loss 1.4204756021499634\n",
      "epoch 26, loss 1.4110004901885986\n",
      "epoch 27, loss 1.4049564599990845\n",
      "epoch 28, loss 1.4014126062393188\n",
      "epoch 29, loss 1.3982223272323608\n",
      "epoch 30, loss 1.3965179920196533\n",
      "epoch 31, loss 1.3949699401855469\n",
      "epoch 32, loss 1.39347243309021\n",
      "epoch 33, loss 1.3918999433517456\n",
      "epoch 34, loss 1.3912415504455566\n",
      "epoch 35, loss 1.3897976875305176\n",
      "epoch 36, loss 1.3887015581130981\n",
      "epoch 37, loss 1.3877824544906616\n",
      "epoch 38, loss 1.3869484663009644\n",
      "epoch 39, loss 1.3857625722885132\n",
      "epoch 40, loss 1.3845335245132446\n",
      "epoch 41, loss 1.3831751346588135\n",
      "epoch 42, loss 1.3824546337127686\n",
      "epoch 43, loss 1.381431221961975\n",
      "epoch 44, loss 1.3801501989364624\n",
      "epoch 45, loss 1.3789485692977905\n",
      "epoch 46, loss 1.3787524700164795\n",
      "epoch 47, loss 1.3777873516082764\n",
      "epoch 48, loss 1.3763233423233032\n",
      "epoch 49, loss 1.3754072189331055\n",
      "epoch 50, loss 1.374428629875183\n",
      "epoch 51, loss 1.3730480670928955\n",
      "epoch 52, loss 1.3724591732025146\n",
      "epoch 53, loss 1.3714040517807007\n",
      "epoch 54, loss 1.3703670501708984\n",
      "epoch 55, loss 1.3693689107894897\n",
      "epoch 56, loss 1.3684120178222656\n",
      "epoch 57, loss 1.3679159879684448\n",
      "epoch 58, loss 1.3668755292892456\n",
      "epoch 59, loss 1.3656597137451172\n",
      "epoch 60, loss 1.3646774291992188\n",
      "epoch 61, loss 1.3638654947280884\n",
      "epoch 62, loss 1.3630059957504272\n",
      "epoch 63, loss 1.362622618675232\n",
      "epoch 64, loss 1.3617955446243286\n",
      "epoch 65, loss 1.3608372211456299\n",
      "epoch 66, loss 1.359781265258789\n",
      "epoch 67, loss 1.3590967655181885\n",
      "epoch 68, loss 1.3582929372787476\n",
      "epoch 69, loss 1.3577826023101807\n",
      "epoch 70, loss 1.35736882686615\n",
      "epoch 71, loss 1.3565822839736938\n",
      "epoch 72, loss 1.3558199405670166\n",
      "epoch 73, loss 1.355370044708252\n",
      "epoch 74, loss 1.35492742061615\n",
      "epoch 75, loss 1.3543473482131958\n",
      "epoch 76, loss 1.3538874387741089\n",
      "epoch 77, loss 1.3532264232635498\n",
      "epoch 78, loss 1.3525856733322144\n",
      "epoch 79, loss 1.3518491983413696\n",
      "epoch 80, loss 1.3511468172073364\n",
      "epoch 81, loss 1.3502594232559204\n",
      "epoch 82, loss 1.3497285842895508\n",
      "epoch 83, loss 1.3489187955856323\n",
      "epoch 84, loss 1.3484846353530884\n",
      "epoch 85, loss 1.3482232093811035\n",
      "epoch 86, loss 1.3480734825134277\n",
      "epoch 87, loss 1.3474177122116089\n",
      "epoch 88, loss 1.3467724323272705\n",
      "epoch 89, loss 1.3464839458465576\n",
      "epoch 90, loss 1.346091866493225\n",
      "epoch 91, loss 1.3454025983810425\n",
      "epoch 92, loss 1.3447145223617554\n",
      "epoch 93, loss 1.3442363739013672\n",
      "epoch 94, loss 1.3437689542770386\n",
      "epoch 95, loss 1.343225359916687\n",
      "epoch 96, loss 1.3426350355148315\n",
      "epoch 97, loss 1.3429089784622192\n",
      "epoch 98, loss 1.3422528505325317\n",
      "epoch 99, loss 1.3416067361831665\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(torch.nn.Sequential):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(8, 1) # One in and one out\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "# our model\n",
    "our_model = LinearRegressionModel()\n",
    "\n",
    "# # move it to GPU\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "# our_model.to(device)\n",
    "\n",
    "# our_model.linear.weight.data = torch.rand((1,8), requires_grad=True)\n",
    "# our_model.linear.bias.data = torch.rand(1, requires_grad=True)\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.RMSprop(our_model.parameters(), lr = 0.0001)\n",
    "\n",
    "# inputs = data.to(device)\n",
    "# target = target.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    for X, y in data_train:\n",
    "        \n",
    "        # Forward pass: Compute predicted y by passing\n",
    "        # x to the model\n",
    "\n",
    "        pred_y = our_model(X)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(pred_y, y)\n",
    "\n",
    "        # Zero gradients, perform a backward pass,\n",
    "        # and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # считаем loss на тренировочных данных\n",
    "    loss = criterion(our_model(X_train), y_train)\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0510,  0.0092, -0.0215,  0.0230, -0.0014, -0.0052, -0.0478, -0.0519]]),\n",
       " tensor([2.0687]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_model.linear.weight.data, our_model.linear.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = (our_model(X_test) - y_test).pow(2).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3342851400375366"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5260, 3.5850, 3.5210,  ..., 0.9230, 0.8470, 0.8940])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbab4d99060>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test[::,7], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
